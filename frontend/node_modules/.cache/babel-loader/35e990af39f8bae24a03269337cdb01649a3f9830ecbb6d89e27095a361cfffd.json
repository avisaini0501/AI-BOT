{"ast":null,"code":"import { Configuration, OpenAIApi } from \"openai\";\nconst configuration = new Configuration({\n  apiKey: \"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\"\n});\nconst openai = new OpenAIApi(configuration);\nexport async function sendMsgToOpenAI(message) {\n  const res = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: message,\n    temperature: 0.7,\n    max_tokens: 256,\n    top_p: 1,\n    frequency_penalty: 0,\n    presense_penalty: 0\n  });\n  return res.data.choices[0].text;\n}","map":{"version":3,"names":["Configuration","OpenAIApi","configuration","apiKey","openai","sendMsgToOpenAI","message","res","createCompletion","model","prompt","temperature","max_tokens","top_p","frequency_penalty","presense_penalty","data","choices","text"],"sources":["C:/Users/Lenovo/Desktop/clone/src/openai.js"],"sourcesContent":["import { Configuration, OpenAIApi } from \"openai\"\r\nconst configuration = new Configuration({ apiKey: \"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\"});\r\nconst openai  = new OpenAIApi(configuration);\r\n\r\nexport async function sendMsgToOpenAI(message) {\r\n    const res = await openai.createCompletion({\r\n        model: \"text-davinci-003\",\r\n        prompt: message,\r\n        temperature: 0.7,\r\n        max_tokens: 256,\r\n        top_p: 1,\r\n        frequency_penalty: 0,\r\n        presense_penalty: 0\r\n    });\r\n    return res.data.choices[0].text;\r\n}"],"mappings":"AAAA,SAASA,aAAa,EAAEC,SAAS,QAAQ,QAAQ;AACjD,MAAMC,aAAa,GAAG,IAAIF,aAAa,CAAC;EAAEG,MAAM,EAAE;AAAqD,CAAC,CAAC;AACzG,MAAMC,MAAM,GAAI,IAAIH,SAAS,CAACC,aAAa,CAAC;AAE5C,OAAO,eAAeG,eAAeA,CAACC,OAAO,EAAE;EAC3C,MAAMC,GAAG,GAAG,MAAMH,MAAM,CAACI,gBAAgB,CAAC;IACtCC,KAAK,EAAE,kBAAkB;IACzBC,MAAM,EAAEJ,OAAO;IACfK,WAAW,EAAE,GAAG;IAChBC,UAAU,EAAE,GAAG;IACfC,KAAK,EAAE,CAAC;IACRC,iBAAiB,EAAE,CAAC;IACpBC,gBAAgB,EAAE;EACtB,CAAC,CAAC;EACF,OAAOR,GAAG,CAACS,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,IAAI;AACnC"},"metadata":{},"sourceType":"module","externalDependencies":[]}